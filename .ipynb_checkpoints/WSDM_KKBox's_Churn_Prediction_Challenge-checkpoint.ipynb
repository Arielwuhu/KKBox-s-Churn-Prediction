{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the datasets are too large, do not push to github!\n",
    "# download the file on the desktop\n",
    "mypath = \"data\"\n",
    "files = [mypath+'/'+str(f) for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create data dictionary and move these 5 files into it.\n",
    "\n",
    "Output of listdir(mypath) should be:\n",
    "\n",
    "data/members_v3.csv.7z \n",
    "\n",
    "data/sample_submission_zero.csv.7z\n",
    "\n",
    "data/train.csv.7z\n",
    "\n",
    "data/transactions.csv.7z\n",
    "\n",
    "data/user_logs.csv.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/members_v3.csv.7z',\n",
       " 'data/sample_submission_zero.csv.7z',\n",
       " 'data/train.csv.7z',\n",
       " 'data/transactions.csv.7z',\n",
       " 'data/user_logs.csv.7z']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary is already created\n"
     ]
    }
   ],
   "source": [
    "if \"unpacked_data\" not in listdir('./'):\n",
    "    os.makedirs(\"./unpacked_data\")\n",
    "else:\n",
    "    print(\"Dictionary is already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [23:38<00:00, 283.70s/it]\n"
     ]
    }
   ],
   "source": [
    "# unpack data\n",
    "import py7zr\n",
    "\n",
    "\n",
    "extract_path = \"unpacked_data\"\n",
    "for file in tqdm.tqdm(files):\n",
    "    with py7zr.SevenZipFile(file, mode='r') as z:\n",
    "        data = z.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(\"unpacked_data/user_logs.csv\")\n",
    "member_dat = pd.read_csv(\"unpacked_data/members_v3.csv\")\n",
    "transactions_dat = pd.read_csv('unpacked_data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions that use to change the datatype according to columns' largest values for memory saving。\n",
    "\n",
    "For integer:\n",
    "For example, the maximum number that int8 can store is 127, and the minimum is - 128;\n",
    "if the largest values for such column is smaller than the value，\n",
    "we change the data type to int8\n",
    "Perform this for all columns include int.\n",
    "\n",
    "For float:\n",
    "We change all features to float32\n",
    "Source: https://www.kaggle.com/jeru666/did-you-think-of-these-features/notebook\n",
    "'''\n",
    "\n",
    "def change_datatype(df):\n",
    "    int_cols = list(df.select_dtypes(include=['int']).columns)\n",
    "    for col in int_cols:\n",
    "        if ((np.max(df[col]) <= 127) and(np.min(df[col] >= -128))):\n",
    "            df[col] = df[col].astype(np.int8)\n",
    "        elif ((np.max(df[col]) <= 32767) and(np.min(df[col] >= -32768))):\n",
    "            df[col] = df[col].astype(np.int16)\n",
    "        elif ((np.max(df[col]) <= 2147483647) and(np.min(df[col] >= -2147483648))):\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        else:\n",
    "            df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "def change_datatype_float(df):\n",
    "    float_cols = list(df.select_dtypes(include=['float']).columns)\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = transactions_dat.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")\n",
    "\n",
    "change_datatype(transactions_dat)\n",
    "change_datatype_float(transactions_dat)\n",
    "\n",
    "mem = transactions_dat.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = member_dat.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")\n",
    "\n",
    "change_datatype(member_dat)\n",
    "change_datatype_float(member_dat)\n",
    "\n",
    "mem = member_dat.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = user_data.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")\n",
    "\n",
    "change_datatype(user_data)\n",
    "change_datatype_float(user_data)\n",
    "\n",
    "mem = user_data.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data and explore correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = pd.read_csv('142A_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.merge(train_dat, user_data, on = 'msno') \n",
    "train2 = pd.merge(train_dat, member_dat, on = 'msno') \n",
    "train3 = pd.merge(train_dat, transactions_dat, on = 'msno') \n",
    "    # system crack if merge all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['gender'].replace({'female':'1', 'male':'0'}, inplace = True)\n",
    "train1.head()\n",
    "train2.head()\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train1.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train2.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train3.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train1.iloc[:,2:]\n",
    "y = train1.loc[:,['is_churn']]\n",
    "lr = LogisticRegression(random_state=0).fit(X, y)\n",
    "lr.predict(X)\n",
    "lr.score(X, y) # Output: 0.9442647435443151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train2.iloc[:,2:]\n",
    "y = train2.loc[:,['is_churn']]\n",
    "lr = LogisticRegression(random_state=0).fit(X, y)\n",
    "lr.predict(X)\n",
    "lr.score(X, y) # Need to debug, dataset has Null value???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train3.iloc[:,2:]\n",
    "y = train3.loc[:,['is_churn']]\n",
    "lr = LogisticRegression(random_state=0).fit(X, y)\n",
    "lr.predict(X)\n",
    "lr.score(X, y) # Output: 0.9568365792473885"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
